{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import gensim, warnings\n",
    "import re  # For preprocessing\n",
    "import pandas as pd  # For data handling\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict  # For word frequency\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zamiana tekstu na listę\n",
    "def Convert(string): \n",
    "    li = list(string.split(\"\\n\"))\n",
    "    return li\n",
    "def Convertcoma(string):\n",
    "    li = list(string.split(\",\"))\n",
    "    return li\n",
    "def ConvNEXT(string):\n",
    "    li = list(string.split(\"NA5T3PNY\"))\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads files\n",
    "file = open(\"TEKST.txt\", \"r\", encoding=\"utf-8\")\n",
    "# zródło: https://pl.wikipedia.org/wiki/Wikipedia:Stopwords\n",
    "stopwords = open(\"stopwordsWIKI.txt\", \"r\", encoding=\"utf8\")\n",
    "searched = open(\"WYSZUKANIA.txt\", \"r\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string = file.read()\n",
    "stop = stopwords.read().lower()\n",
    "stop=re.sub('[\\s]+', '', stop) # usuwanie spacji z listy\n",
    "# print(stop)\n",
    "# Replaces escape character with space\n",
    "stopwords_list = Convertcoma(stop)\n",
    "# print(stopwords_list)\n",
    "# print(len(stopwords_list))\n",
    "wysz = searched.read().lower()\n",
    "szukane = Convert(wysz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1960452\n"
    }
   ],
   "source": [
    "string_org = file.read() #wczytanie pliku zawierającego wszystkie artykuły\n",
    "print(len(string_org.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zamknięcie otwartych plików\n",
    "file.close()\n",
    "stopwords.close()\n",
    "searched.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1930115\n"
    }
   ],
   "source": [
    "# usunięcie wszystkich elementów tekstu np.'== Pliki zewnętrzne ==' które kopiowane z wikipedii są najo nagłówki kolejnych akapitów\n",
    "\n",
    "# *     - 0 or more\n",
    "# +     - 1 or more\n",
    "# ?     - 0 or One\n",
    "# {3}   - exact number\n",
    "# {3,4} - range of numbers min max\n",
    "\n",
    "string=re.sub('==[\\s*\\w*\\s*]*==',' ',string_org) \n",
    "print(len(string.split(' '))) #wyświetlenie ile jest wyrazów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1940042\n"
    }
   ],
   "source": [
    "# usunięcie wszystkiego poza wyrazami i liczbami - uwuwanie znaków specjalnych :;,.*=+-/\n",
    "string=re.sub('[^\\w]+', ' ', string) \n",
    "print(len(string.split(' '))) #wyświetlenie ile jest wyrazów\n",
    "# tutaj po usunięciu powstały nadmierne spacje które liczone są jako oddnielny ciąg znaków"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1546285\n"
    }
   ],
   "source": [
    "# usunięcie wszystkich pojedynczych i podwójnych znaków np. r gdy coś było oznaczone jako rok \n",
    "# lub skróty tupu m.in. w.-wiek\n",
    "string=' '.join( [w for w in string.split() if len(w)>2]) \n",
    "print(len(string.split(' '))) #wyświetlenie ile jest wyrazów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Cyclops cunningtoni gatunek widłonoga rodziny Cyclopidae nazwa naukowa gatunku została raz pierwszy opublikowana 1909 roku przez norweskiego hydrobiologa Georga Ossiana Sarsa Walter Chad 2012 Cyclops cunningtoni Sars 1909 Walter Boxshall 2012 World Copepoda database Geraadpleegd via World Register Marine Species \n"
    }
   ],
   "source": [
    "#Rozdzielenie artykułów z jednego długiego tekstu na każdy z osobna i zapisanie jako element listy\n",
    "#Użyto do tego ciągu znaków 'NA5T3PNY' który był dodawany podczas zapisu na końcu każdego artykułu\n",
    "tokeX=ConvNEXT(string)\n",
    "print(tokeX[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "4865\n1280748\n"
    }
   ],
   "source": [
    "tokeXS=[]\n",
    "q=0\n",
    "for s in range(len(tokeX)):\n",
    "    k=tokeX[s]\n",
    "    k=k.lower() #małe litery\n",
    "    # usunięcie wszystkich słów często występujących w tekście (lista słów z wikipedii)\n",
    "    k=' '.join( [w for w in k.split() if w not in stopwords_list])\n",
    "    k=re.sub('[\\d]+', '',k) #usuwanie liczb\n",
    "#     k=re.sub('[\\s]+', ' ',k) #usuwanie nadmiernych spacji\n",
    "    k=re.sub('[^\\w]+', ' ',k) #usunięcie wszystkiego poza wyrazami - pozbycie sie nadmiernych spacji\n",
    "    tokeXS.append(k) \n",
    "    a=len(k.split())\n",
    "    q+=a\n",
    "print(len(tokeXS))\n",
    "print(q) #wyświetlenie ile jest wyrazów\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Tekst\n0     kielisznik zaroślowy calystegia sepium gatunek...\n1     model ekv tranzystora mos obliczeniowych model...\n2      matsuobasho planetoida pasa głównego asteroid...\n3     porwana historia carliny white ang abducted th...\n4     zespół szkół poligraficznych marszałka józefa ...\n...                                                 ...\n4860  santa lucía reforma niewielkie miasto południo...\n4861  piasek mały wieś polsce położona województwie ...\n4862  gsm ang global system for mobile communication...\n4863  teoria budżetu dyscyplina naukowa zajmująca po...\n4864                                                   \n\n[4865 rows x 1 columns]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(4865, 1)"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# wrzucenie wszystkich artykułów po oczyszczeniu do data frame\n",
    "df = pd.DataFrame(tokeXS, columns =['Tekst'])\n",
    "print(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Tekst    0\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "df.isnull().sum() #puste wartości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0       kielisznik zaroślowy calystegia sepium gatunek...\n1       model ekv tranzystora mos obliczeniowych model...\n2        matsuobasho planetoida pasa głównego asteroid...\n3       porwana historia carliny white ang abducted th...\n4       zespół szkół poligraficznych marszałka józefa ...\n                              ...                        \n4860    santa lucía reforma niewielkie miasto południo...\n4861    piasek mały wieś polsce położona województwie ...\n4862    gsm ang global system for mobile communication...\n4863    teoria budżetu dyscyplina naukowa zajmująca po...\n4864                                                     \nName: Tekst, Length: 4865, dtype: object\n"
    }
   ],
   "source": [
    "print(df['Tekst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podział każdego artykułu na pojedyncze słowa \n",
    "sent = [row.split() for row in df['Tekst']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'list'>\n['densmore', 'den', 'ronald', 'dover', 'kwietnia', 'warrington', 'brytyjski', 'polityk', 'poseł', 'izby', 'gmin', 'deputowany', 'parlamentu', 'europejskiego', 'ukończył', 'studia', 'inżynierskie', 'university', 'manchester', 'pracował', 'przedsiębiorstwach', 'konstrukcyjnych', 'dyrektorem', 'krajowej', 'agencji', 'budownictwa', 'zasiadał', 'radzie', 'dzielnicy', 'barnet', 'londynie', 'cztery', 'kadencje', 'deputowanym', 'izby', 'gmin', 'latach', 'ramienia', 'partii', 'konserwatywnej', 'sprawował', 'mandat', 'posła', 'parlamentu', 'europejskiego', 'należał', 'frakcji', 'chadeckiej', 'pracował', 'komisji', 'budżetowej', 'komisji', 'przemysłu', 'badań', 'naukowych', 'energii', 'den', 'dover', 'przewodniczącym', 'torysów', 'europarlamencie', 'zrezygnował', 'ujawnieniu', 'dziewięć', 'wypłacił', 'publicznych', 'funduszy', 'tys', 'funtów', 'swojej', 'żonie', 'córce', 'wyniku', 'wewnętrznego', 'śledztwa', 'nakazano', 'zwrócić', 'sumy', 'usunięty', 'partii', 'konserwatywnej']\n"
    }
   ],
   "source": [
    "print(type(sent))\n",
    "print(sent[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO - 13:43:27: collecting all words and their counts\nINFO - 13:43:27: PROGRESS: at sentence #0, processed 0 words and 0 word types\nINFO - 13:43:29: collected 1125923 word types from a corpus of 1280748 words (unigram + bigrams) and 4865 sentences\nINFO - 13:43:29: using 1125923 counts as vocab in Phrases<0 vocab, min_count=20, threshold=10.0, max_vocab_size=40000000>\n"
    }
   ],
   "source": [
    "phrases = Phrases(sent, min_count=20, progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO - 13:43:29: source_vocab length 1125923\nINFO - 13:43:38: Phraser built with 1280 phrasegrams\n"
    }
   ],
   "source": [
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = bigram[sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sprawdzenie efektywności oczyszczania tektu poprzez sprawdzenie jakie słowa występują najczęściej w pliku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "187632"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq) #ile jest różnych unikalnych słów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wyświetlamy 10 najczęściej występujących słów globalnie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['latach',\n 'polski',\n 'the',\n 'ang',\n 'została',\n 'miasta',\n 'stycznia',\n 'maja',\n 'polsce',\n 'września']"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "12\n"
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count() # Liczba obsługiwanych wątków przez procesor (u mnie 12)\n",
    "print(cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nadajemy parametry dla modelu word2vec (w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=30, #ignoruje wszystkie wyrazy które wystąpiły żadziej niż-(2,100)\n",
    "                     window=5, #max dystans pomiedzy słowem rozpatrywanym a przewidywanym w zdaniu-(2,10)\n",
    "                     size=300, #wymiar wektorów - (50,300)\n",
    "                     sample=6e-5, #próg dla którego bardzo często występujące słowa będą rzadziej brane pod uwagę (Duży wpływ)-(0,1e-5)\n",
    "                     alpha=0.03, # początkowy wsp. uczenia - (0.01,0.05)\n",
    "                     workers=cores-1) # ile wątków procesora wykorzystujemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UWAGA\n",
    "tutaj można pominąć etap budowy słownika i przejść do wytrenowanego już modelu\n",
    "\n",
    "Parametry wytrenowanego modelu:\n",
    "\n",
    "min_count=30, #ignoruje wszystkie wyrazy które wystąpiły żadziej niż-(2,100)\n",
    "\n",
    "window=5, #max dystans pomiedzy słowem rozpatrywanym a przewidywanym w zdaniu-(2,10)\n",
    "\n",
    "size=300, #wymiar wektorów - (50,300)\n",
    "\n",
    "sample=6e-5, #próg dla którego bardzo często występujące słowa będą rzadziej brane pod uwagę (Duży wpływ)-(0,1e-5)\n",
    "\n",
    "alpha=0.03, # początkowy wsp. uczenia - (0.01,0.05)\n",
    "\n",
    "workers=cores-1 # ile wątków procesora wykorzystujemy\n",
    "\n",
    "### Nazwa pliku: w2v_model.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzymy słownik "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO - 21:48:45: collecting all words and their counts\nINFO - 21:48:45: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\nINFO - 21:48:48: collected 187632 word types from a corpus of 1232606 raw words and 4865 sentences\nINFO - 21:48:48: Loading a fresh vocabulary\nINFO - 21:48:48: effective_min_count=30 retains 7161 unique words (3% of original 187632, drops 180471)\nINFO - 21:48:48: effective_min_count=30 leaves 643936 word corpus (52% of original 1232606, drops 588670)\nINFO - 21:48:48: deleting the raw counts dictionary of 187632 items\nINFO - 21:48:48: sample=6e-05 downsamples 1554 most-common words\nINFO - 21:48:48: downsampling leaves estimated 487053 word corpus (75.6% of prior 643936)\nINFO - 21:48:48: estimated required memory for 7161 words and 300 dimensions: 20766900 bytes\nINFO - 21:48:48: resetting layer weights\nTime to build vocab: 0.08 mins\n"
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "ctors.Vocab at 0x17e92037ec8>,\n 'leży': <gensim.models.keyedvectors.Vocab at 0x17e92037048>,\n 'dawnej': <gensim.models.keyedvectors.Vocab at 0x17e920370c8>,\n 'krakowskiej': <gensim.models.keyedvectors.Vocab at 0x17e92037148>,\n 'historycznej': <gensim.models.keyedvectors.Vocab at 0x17e920371c8>,\n 'danych': <gensim.models.keyedvectors.Vocab at 0x17e92037208>,\n 'miało': <gensim.models.keyedvectors.Vocab at 0x17e92037248>,\n 'mieszkańców': <gensim.models.keyedvectors.Vocab at 0x17e92037288>,\n 'dukli': <gensim.models.keyedvectors.Vocab at 0x17e920372c8>,\n 'mieści': <gensim.models.keyedvectors.Vocab at 0x17e92037388>,\n 'policji': <gensim.models.keyedvectors.Vocab at 0x17e920373c8>,\n 'ośrodek': <gensim.models.keyedvectors.Vocab at 0x17e92037408>,\n 'zdrowia': <gensim.models.keyedvectors.Vocab at 0x17e92037448>,\n 'dom': <gensim.models.keyedvectors.Vocab at 0x17e920374c8>,\n 'pttk': <gensim.models.keyedvectors.Vocab at 0x17e92037508>,\n 'ratusz': <gensim.models.keyedvectors.Vocab at 0x17e920375c8>,\n 'młodzieżowe': <gensim.models.keyedvectors.Vocab at 0x17e92037608>,\n 'restauracji': <gensim.models.keyedvectors.Vocab at 0x17e92037648>,\n 'boisko': <gensim.models.keyedvectors.Vocab at 0x17e92037688>,\n 'sportowe': <gensim.models.keyedvectors.Vocab at 0x17e92037708>,\n 'najstarsze': <gensim.models.keyedvectors.Vocab at 0x17e92037748>,\n 'brązu': <gensim.models.keyedvectors.Vocab at 0x17e92037788>,\n 'żelaza': <gensim.models.keyedvectors.Vocab at 0x17e920377c8>,\n 'okolicy': <gensim.models.keyedvectors.Vocab at 0x17e92037808>,\n 'okresie': <gensim.models.keyedvectors.Vocab at 0x17e92037848>,\n 'wpływów': <gensim.models.keyedvectors.Vocab at 0x17e92037888>,\n 'kultury': <gensim.models.keyedvectors.Vocab at 0x17e92037948>,\n 'terenie': <gensim.models.keyedvectors.Vocab at 0x17e92037a08>,\n 'nowej': <gensim.models.keyedvectors.Vocab at 0x17e92037a48>,\n 'mianem': <gensim.models.keyedvectors.Vocab at 0x17e92037b48>,\n 'tworzenia': <gensim.models.keyedvectors.Vocab at 0x17e92037b88>,\n 'wpływ': <gensim.models.keyedvectors.Vocab at 0x17e92037bc8>,\n 'miała': <gensim.models.keyedvectors.Vocab at 0x17e92037c08>,\n 'czego': <gensim.models.keyedvectors.Vocab at 0x17e92037c48>,\n 'przykładem': <gensim.models.keyedvectors.Vocab at 0x17e92037cc8>,\n 'tzw': <gensim.models.keyedvectors.Vocab at 0x17e92037d08>,\n 'stanowił': <gensim.models.keyedvectors.Vocab at 0x17e92037d48>,\n 'warunki': <gensim.models.keyedvectors.Vocab at 0x17e92037d88>,\n 'czasach': <gensim.models.keyedvectors.Vocab at 0x17e92037e08>,\n 'viii': <gensim.models.keyedvectors.Vocab at 0x17e92037e88>,\n 'rozpoczął': <gensim.models.keyedvectors.Vocab at 0x17e92037f08>,\n 'większych': <gensim.models.keyedvectors.Vocab at 0x17e92037f88>,\n 'ziemie': <gensim.models.keyedvectors.Vocab at 0x17e92037fc8>,\n 'plemię': <gensim.models.keyedvectors.Vocab at 0x17e9203bf08>,\n 'raczej': <gensim.models.keyedvectors.Vocab at 0x17e9203b088>,\n 'związek': <gensim.models.keyedvectors.Vocab at 0x17e9203b048>,\n 'tworzących': <gensim.models.keyedvectors.Vocab at 0x17e9203b108>,\n 'bliżej': <gensim.models.keyedvectors.Vocab at 0x17e9203b148>,\n 'czech': <gensim.models.keyedvectors.Vocab at 0x17e9203b188>,\n 'potem': <gensim.models.keyedvectors.Vocab at 0x17e9203b0c8>,\n 'pierwsza_wzmianka': <gensim.models.keyedvectors.Vocab at 0x17e9203b248>,\n 'wsi': <gensim.models.keyedvectors.Vocab at 0x17e9203b208>,\n 'miejscu': <gensim.models.keyedvectors.Vocab at 0x17e9203b348>,\n 'początku': <gensim.models.keyedvectors.Vocab at 0x17e9203b388>,\n 'swojego': <gensim.models.keyedvectors.Vocab at 0x17e9203b3c8>,\n 'istnienia': <gensim.models.keyedvectors.Vocab at 0x17e9203b308>,\n 'własnością': <gensim.models.keyedvectors.Vocab at 0x17e9203b448>,\n 'kanclerz': <gensim.models.keyedvectors.Vocab at 0x17e9203b408>,\n 'janusz': <gensim.models.keyedvectors.Vocab at 0x17e9203b4c8>,\n 'otrzymał': <gensim.models.keyedvectors.Vocab at 0x17e9203b488>,\n 'swoich': <gensim.models.keyedvectors.Vocab at 0x17e9203b508>,\n 'przekazał': <gensim.models.keyedvectors.Vocab at 0x17e9203b608>,\n 'dobra': <gensim.models.keyedvectors.Vocab at 0x17e9203b648>,\n 'ustanowił': <gensim.models.keyedvectors.Vocab at 0x17e9203b588>,\n 'pierwszą': <gensim.models.keyedvectors.Vocab at 0x17e9203b688>,\n 'którą': <gensim.models.keyedvectors.Vocab at 0x17e9203b6c8>,\n 'kazimierz': <gensim.models.keyedvectors.Vocab at 0x17e9203b788>,\n 'wydał': <gensim.models.keyedvectors.Vocab at 0x17e9203b708>,\n 'akt': <gensim.models.keyedvectors.Vocab at 0x17e9203b7c8>,\n 'następne': <gensim.models.keyedvectors.Vocab at 0x17e9203b808>,\n 'prawa_miejskie': <gensim.models.keyedvectors.Vocab at 0x17e9203b848>,\n 'otrzymała': <gensim.models.keyedvectors.Vocab at 0x17e9203b888>,\n 'stanisław': <gensim.models.keyedvectors.Vocab at 0x17e9203b948>,\n 'ponownie': <gensim.models.keyedvectors.Vocab at 0x17e9203b988>,\n 'wśród': <gensim.models.keyedvectors.Vocab at 0x17e9203b8c8>,\n 'licznych': <gensim.models.keyedvectors.Vocab at 0x17e9203b9c8>,\n 'przedstawicieli': <gensim.models.keyedvectors.Vocab at 0x17e9203ba48>,\n 'właścicieli': <gensim.models.keyedvectors.Vocab at 0x17e9203ba88>,\n 'rodu': <gensim.models.keyedvectors.Vocab at 0x17e9203bac8>,\n 'kasztelan': <gensim.models.keyedvectors.Vocab at 0x17e9203ba08>,\n 'marszałek': <gensim.models.keyedvectors.Vocab at 0x17e9203bb08>,\n 'dowództwem': <gensim.models.keyedvectors.Vocab at 0x17e9203bb88>,\n 'uczestniczył': <gensim.models.keyedvectors.Vocab at 0x17e9203bb48>,\n 'bitwie': <gensim.models.keyedvectors.Vocab at 0x17e9203bbc8>,\n 'podpisał': <gensim.models.keyedvectors.Vocab at 0x17e9203bc08>,\n 'królem': <gensim.models.keyedvectors.Vocab at 0x17e9203bc48>,\n 'wojsk': <gensim.models.keyedvectors.Vocab at 0x17e9203bcc8>,\n 'macieja': <gensim.models.keyedvectors.Vocab at 0x17e9203bc88>,\n 'wymiany': <gensim.models.keyedvectors.Vocab at 0x17e9203bd48>,\n 'koło': <gensim.models.keyedvectors.Vocab at 0x17e9203bd08>,\n 'króla': <gensim.models.keyedvectors.Vocab at 0x17e9203bd88>,\n 'aleksandra': <gensim.models.keyedvectors.Vocab at 0x17e9203bdc8>,\n 'oparty': <gensim.models.keyedvectors.Vocab at 0x17e9203be88>,\n 'niemieckim': <gensim.models.keyedvectors.Vocab at 0x17e9203bf48>,\n 'śmierci': <gensim.models.keyedvectors.Vocab at 0x17e9289d308>,\n 'męża': <gensim.models.keyedvectors.Vocab at 0x17e9289dd48>,\n 'ewa': <gensim.models.keyedvectors.Vocab at 0x17e9289ddc8>,\n 'miejscowości': <gensim.models.keyedvectors.Vocab at 0x17e9289df88>,\n 'żona': <gensim.models.keyedvectors.Vocab at 0x17e9289d148>,\n 'anna': <gensim.models.keyedvectors.Vocab at 0x17e9289d0c8>,\n 'jan': <gensim.models.keyedvectors.Vocab at 0x17e9289dd08>,\n 'krzysztof': <gensim.models.keyedvectors.Vocab at 0x17e9289d688>,\n 'jordan': <gensim.models.keyedvectors.Vocab at 0x17e9289d9c8>,\n 'herbu': <gensim.models.keyedvectors.Vocab at 0x17e9289d448>,\n 'krakowski': <gensim.models.keyedvectors.Vocab at 0x17e92039d48>,\n 'potrzebny_przypis': <gensim.models.keyedvectors.Vocab at 0x17e92039f08>,\n 'zamek': <gensim.models.keyedvectors.Vocab at 0x17e92039ec8>,\n 'zygmunta': <gensim.models.keyedvectors.Vocab at 0x17e92039fc8>,\n 'starego': <gensim.models.keyedvectors.Vocab at 0x17e92039f48>,\n 'miasta': <gensim.models.keyedvectors.Vocab at 0x17e92039048>,\n 'dwóch': <gensim.models.keyedvectors.Vocab at 0x17e92039088>,\n 'brat': <gensim.models.keyedvectors.Vocab at 0x17e920390c8>,\n 'drugiej': <gensim.models.keyedvectors.Vocab at 0x17e92039108>,\n 'żony': <gensim.models.keyedvectors.Vocab at 0x17e92039148>,\n 'ojca': <gensim.models.keyedvectors.Vocab at 0x17e92039188>,\n 'anny': <gensim.models.keyedvectors.Vocab at 0x17e920391c8>,\n 'zofii': <gensim.models.keyedvectors.Vocab at 0x17e92039248>,\n 'ważnym': <gensim.models.keyedvectors.Vocab at 0x17e92039288>,\n 'skład': <gensim.models.keyedvectors.Vocab at 0x17e920392c8>,\n 'komory': <gensim.models.keyedvectors.Vocab at 0x17e92039308>,\n 'rozpoczęła': <gensim.models.keyedvectors.Vocab at 0x17e92039348>,\n 'dzięki': <gensim.models.keyedvectors.Vocab at 0x17e92039408>,\n 'mogło': <gensim.models.keyedvectors.Vocab at 0x17e92039448>,\n 'wraz': <gensim.models.keyedvectors.Vocab at 0x17e92039488>,\n 'sprzedał': <gensim.models.keyedvectors.Vocab at 0x17e920394c8>,\n 'wyprawy': <gensim.models.keyedvectors.Vocab at 0x17e92039508>,\n 'matka': <gensim.models.keyedvectors.Vocab at 0x17e92039548>,\n 'swą': <gensim.models.keyedvectors.Vocab at 0x17e92039588>,\n 'potok': <gensim.models.keyedvectors.Vocab at 0x17e920395c8>,\n 'znanym': <gensim.models.keyedvectors.Vocab at 0x17e92039608>,\n 'jerzego': <gensim.models.keyedvectors.Vocab at 0x17e92039648>,\n 'miastem': <gensim.models.keyedvectors.Vocab at 0x17e92039688>,\n 'handlowym': <gensim.models.keyedvectors.Vocab at 0x17e920396c8>,\n 'trakcie': <gensim.models.keyedvectors.Vocab at 0x17e92039708>,\n 'polski': <gensim.models.keyedvectors.Vocab at 0x17e92039748>,\n 'przełęcz': <gensim.models.keyedvectors.Vocab at 0x17e92039788>,\n 'węgry': <gensim.models.keyedvectors.Vocab at 0x17e920397c8>,\n 'handlu': <gensim.models.keyedvectors.Vocab at 0x17e92039808>,\n 'xvi_wieku': <gensim.models.keyedvectors.Vocab at 0x17e92039848>,\n 'znalazła': <gensim.models.keyedvectors.Vocab at 0x17e92039888>,\n 'dwoma': <gensim.models.keyedvectors.Vocab at 0x17e920398c8>,\n 'franciszek': <gensim.models.keyedvectors.Vocab at 0x17e92039948>,\n 'pałacu': <gensim.models.keyedvectors.Vocab at 0x17e92039988>,\n 'stycznia': <gensim.models.keyedvectors.Vocab at 0x17e92039a48>,\n 'jana': <gensim.models.keyedvectors.Vocab at 0x17e92039a88>,\n 'kazimierza': <gensim.models.keyedvectors.Vocab at 0x17e92039b08>,\n 'śląska': <gensim.models.keyedvectors.Vocab at 0x17e92039b48>,\n 'szwedzkiego': <gensim.models.keyedvectors.Vocab at 0x17e92039b88>,\n 'marca': <gensim.models.keyedvectors.Vocab at 0x17e92039bc8>,\n 'jarosławiu': <gensim.models.keyedvectors.Vocab at 0x17e92039c08>,\n 'sióstr': <gensim.models.keyedvectors.Vocab at 0x17e92039c48>,\n 'zmarła': <gensim.models.keyedvectors.Vocab at 0x17e92039c88>,\n 'król': <gensim.models.keyedvectors.Vocab at 0x17e92039cc8>,\n 'udał': <gensim.models.keyedvectors.Vocab at 0x17e92039d08>,\n 'lwowa': <gensim.models.keyedvectors.Vocab at 0x17e92039dc8>,\n 'złożył': <gensim.models.keyedvectors.Vocab at 0x17e92039e08>,\n 'rok_później': <gensim.models.keyedvectors.Vocab at 0x17e92039e48>,\n 'wojska': <gensim.models.keyedvectors.Vocab at 0x17e92050708>,\n 'zmarł': <gensim.models.keyedvectors.Vocab at 0x17e92050c48>,\n 'rosjan': <gensim.models.keyedvectors.Vocab at 0x17e92050f08>,\n 'swoją': <gensim.models.keyedvectors.Vocab at 0x17e92050f88>,\n 'połowę': <gensim.models.keyedvectors.Vocab at 0x17e92078048>,\n 'stali': <gensim.models.keyedvectors.Vocab at 0x17e92078088>,\n 'stale': <gensim.models.keyedvectors.Vocab at 0x17e92078108>,\n 'jerzy': <gensim.models.keyedvectors.Vocab at 0x17e920780c8>,\n 'august': <gensim.models.keyedvectors.Vocab at 0x17e92078208>,\n 'poślubił': <gensim.models.keyedvectors.Vocab at 0x17e920781c8>,\n 'córkę': <gensim.models.keyedvectors.Vocab at 0x17e92078248>,\n 'henryka': <gensim.models.keyedvectors.Vocab at 0x17e920782c8>,\n 'ministra': <gensim.models.keyedvectors.Vocab at 0x17e92078308>,\n 'skarbu': <gensim.models.keyedvectors.Vocab at 0x17e92078348>,\n 'saksonii': <gensim.models.keyedvectors.Vocab at 0x17e92078288>,\n 'dworze': <gensim.models.keyedvectors.Vocab at 0x17e920783c8>,\n 'augusta': <gensim.models.keyedvectors.Vocab at 0x17e92078408>,\n 'poniatowskiego': <gensim.models.keyedvectors.Vocab at 0x17e920784c8>,\n 'stracił': <gensim.models.keyedvectors.Vocab at 0x17e92078388>,\n 'wpływy': <gensim.models.keyedvectors.Vocab at 0x17e920785c8>,\n 'żoną': <gensim.models.keyedvectors.Vocab at 0x17e92078688>,\n 'życia': <gensim.models.keyedvectors.Vocab at 0x17e92078608>,\n 'politycznego': <gensim.models.keyedvectors.Vocab at 0x17e92078788>,\n 'umieścił': <gensim.models.keyedvectors.Vocab at 0x17e920787c8>,\n 'teatr': <gensim.models.keyedvectors.Vocab at 0x17e92078748>,\n 'powstają': <gensim.models.keyedvectors.Vocab at 0x17e92078808>,\n 'kościoły': <gensim.models.keyedvectors.Vocab at 0x17e92078848>,\n 'siedzibą': <gensim.models.keyedvectors.Vocab at 0x17e920788c8>,\n 'centrum': <gensim.models.keyedvectors.Vocab at 0x17e92078948>,\n 'rzeczypospolitej': <gensim.models.keyedvectors.Vocab at 0x17e92078908>,\n 'nadał': <gensim.models.keyedvectors.Vocab at 0x17e92078988>,\n 'miastu': <gensim.models.keyedvectors.Vocab at 0x17e920789c8>,\n 'nauczania': <gensim.models.keyedvectors.Vocab at 0x17e92078a08>,\n 'dzieci': <gensim.models.keyedvectors.Vocab at 0x17e92078a88>,\n 'wyznanie': <gensim.models.keyedvectors.Vocab at 0x17e92078a48>,\n 'przywódcy': <gensim.models.keyedvectors.Vocab at 0x17e92078cc8>,\n 'terenu': <gensim.models.keyedvectors.Vocab at 0x17e92078d08>,\n 'zgromadzenie': <gensim.models.keyedvectors.Vocab at 0x17e92078bc8>,\n 'dniu': <gensim.models.keyedvectors.Vocab at 0x17e92078d88>,\n 'lipca': <gensim.models.keyedvectors.Vocab at 0x17e92078dc8>,\n 'odbył': <gensim.models.keyedvectors.Vocab at 0x17e92078d48>,\n 'generalny': <gensim.models.keyedvectors.Vocab at 0x17e92078e48>,\n 'zjazd': <gensim.models.keyedvectors.Vocab at 0x17e92078e88>,\n 'szlachty': <gensim.models.keyedvectors.Vocab at 0x17e92078fc8>,\n 'ogłoszono': <gensim.models.keyedvectors.Vocab at 0x17e92079088>,\n 'konfederacji': <gensim.models.keyedvectors.Vocab at 0x17e92079108>,\n 'wybrano': <gensim.models.keyedvectors.Vocab at 0x17e92079208>,\n 'jakuba': <gensim.models.keyedvectors.Vocab at 0x17e92079248>,\n 'ignacego': <gensim.models.keyedvectors.Vocab at 0x17e920791c8>,\n 'spod': <gensim.models.keyedvectors.Vocab at 0x17e92079348>,\n 'wybrany': <gensim.models.keyedvectors.Vocab at 0x17e92079308>,\n 'krakowa': <gensim.models.keyedvectors.Vocab at 0x17e92079388>,\n 'swoim': <gensim.models.keyedvectors.Vocab at 0x17e920793c8>,\n 'obronie': <gensim.models.keyedvectors.Vocab at 0x17e920794c8>,\n 'krakowskiego': <gensim.models.keyedvectors.Vocab at 0x17e92079608>,\n 'zamku': <gensim.models.keyedvectors.Vocab at 0x17e92079648>,\n 'wyszedł': <gensim.models.keyedvectors.Vocab at 0x17e92079408>,\n 'rosyjskiego': <gensim.models.keyedvectors.Vocab at 0x17e92079708>,\n 'więzienia': <gensim.models.keyedvectors.Vocab at 0x17e92079748>,\n 'maria': <gensim.models.keyedvectors.Vocab at 0x17e92079948>,\n 'władze': <gensim.models.keyedvectors.Vocab at 0x17e920796c8>,\n 'najważniejsze': <gensim.models.keyedvectors.Vocab at 0x17e920799c8>,\n 'pisma': <gensim.models.keyedvectors.Vocab at 0x17e92079a08>,\n 'kontakty': <gensim.models.keyedvectors.Vocab at 0x17e92079a48>,\n 'biskupem': <gensim.models.keyedvectors.Vocab at 0x17e92079988>,\n 'dowódca': <gensim.models.keyedvectors.Vocab at 0x17e92079b48>,\n 'marii': <gensim.models.keyedvectors.Vocab at 0x17e92079b88>,\n 'pierwszego': <gensim.models.keyedvectors.Vocab at 0x17e92079cc8>,\n 'lutego': <gensim.models.keyedvectors.Vocab at 0x17e92079ec8>,\n 'wspólnie': <gensim.models.keyedvectors.Vocab at 0x17e92079d08>,\n 'zamachu': <gensim.models.keyedvectors.Vocab at 0x17e9208fc08>,\n 'żonę': <gensim.models.keyedvectors.Vocab at 0x17e9208fd48>,\n 'letniego': <gensim.models.keyedvectors.Vocab at 0x17e9208f9c8>,\n 'wówczas': <gensim.models.keyedvectors.Vocab at 0x17e9208f388>,\n 'małżeństwo': <gensim.models.keyedvectors.Vocab at 0x17e9208fa48>,\n 'dokonano': <gensim.models.keyedvectors.Vocab at 0x17e9208f2c8>,\n 'okolicach': <gensim.models.keyedvectors.Vocab at 0x17e9208f588>,\n 'druga': <gensim.models.keyedvectors.Vocab at 0x17e9208f648>,\n 'wersji': <gensim.models.keyedvectors.Vocab at 0x17e9208f748>,\n 'oficjalnie': <gensim.models.keyedvectors.Vocab at 0x17e9208f708>,\n 'rodzinę': <gensim.models.keyedvectors.Vocab at 0x17e9208f148>,\n 'innej': <gensim.models.keyedvectors.Vocab at 0x17e9208fe08>,\n 'walki': <gensim.models.keyedvectors.Vocab at 0x17e9208fe48>,\n 'korpusu': <gensim.models.keyedvectors.Vocab at 0x17e9208f788>,\n 'gen': <gensim.models.keyedvectors.Vocab at 0x17e9208f7c8>,\n 'oporu': <gensim.models.keyedvectors.Vocab at 0x17e9208f8c8>,\n 'zajęły': <gensim.models.keyedvectors.Vocab at 0x17e9208f908>,\n 'oddziały': <gensim.models.keyedvectors.Vocab at 0x17e9208f548>,\n 'broń': <gensim.models.keyedvectors.Vocab at 0x17e9207b108>,\n 'zostały': <gensim.models.keyedvectors.Vocab at 0x17e9207b148>,\n 'armii': <gensim.models.keyedvectors.Vocab at 0x17e9207b0c8>,\n 'grudnia': <gensim.models.keyedvectors.Vocab at 0x17e9207b208>,\n 'ślub': <gensim.models.keyedvectors.Vocab at 0x17e9207b248>,\n 'gospodarzy': <gensim.models.keyedvectors.Vocab at 0x17e9207b2c8>,\n 'tadeusz': <gensim.models.keyedvectors.Vocab at 0x17e9207b1c8>,\n 'stała': <gensim.models.keyedvectors.Vocab at 0x17e9207b308>,\n 'stolicą': <gensim.models.keyedvectors.Vocab at 0x17e9207b388>,\n 'jednego': <gensim.models.keyedvectors.Vocab at 0x17e9207b3c8>,\n 'pochowany': <gensim.models.keyedvectors.Vocab at 0x17e9207b408>,\n 'franciszka': <gensim.models.keyedvectors.Vocab at 0x17e9207b488>,\n 'helena': <gensim.models.keyedvectors.Vocab at 0x17e9207b348>,\n 'wojciecha': <gensim.models.keyedvectors.Vocab at 0x17e9207b4c8>,\n 'mjr': <gensim.models.keyedvectors.Vocab at 0x17e9207b548>,\n 'województwa': <gensim.models.keyedvectors.Vocab at 0x17e9207b5c8>,\n 'powróciła': <gensim.models.keyedvectors.Vocab at 0x17e9207b608>,\n 'odmówił': <gensim.models.keyedvectors.Vocab at 0x17e9207b6c8>,\n 'wojskowego': <gensim.models.keyedvectors.Vocab at 0x17e9207b648>,\n 'wsparcia': <gensim.models.keyedvectors.Vocab at 0x17e9207b748>,\n 'powstania': <gensim.models.keyedvectors.Vocab at 0x17e9207b7c8>,\n 'adam': <gensim.models.keyedvectors.Vocab at 0x17e9207b888>,\n 'car': <gensim.models.keyedvectors.Vocab at 0x17e9207b908>,\n 'mikołaj': <gensim.models.keyedvectors.Vocab at 0x17e9207b988>,\n 'odbywał': <gensim.models.keyedvectors.Vocab at 0x17e9207ba48>,\n 'przegląd': <gensim.models.keyedvectors.Vocab at 0x17e9207ba08>,\n 'siedziby': <gensim.models.keyedvectors.Vocab at 0x17e9207bac8>,\n 'początkach': <gensim.models.keyedvectors.Vocab at 0x17e9207ba88>,\n 'xix_wieku': <gensim.models.keyedvectors.Vocab at 0x17e9207bb88>,\n 'stanie': <gensim.models.keyedvectors.Vocab at 0x17e9207bc48>,\n 'ostatecznie': <gensim.models.keyedvectors.Vocab at 0x17e9207bcc8>,\n 'znaczeniu': <gensim.models.keyedvectors.Vocab at 0x17e9207bbc8>,\n 'gospodarczego': <gensim.models.keyedvectors.Vocab at 0x17e9207bd08>,\n 'linii': <gensim.models.keyedvectors.Vocab at 0x17e9207bd88>,\n 'kolejowych': <gensim.models.keyedvectors.Vocab at 0x17e9207bd48>,\n 'linii_kolejowej': <gensim.models.keyedvectors.Vocab at 0x17e9207be08>,\n 'gospodarcze': <gensim.models.keyedvectors.Vocab at 0x17e9207be48>,\n 'wojna_światowa': <gensim.models.keyedvectors.Vocab at 0x17e9207bf48>,\n 'rosyjskie': <gensim.models.keyedvectors.Vocab at 0x17e9207d408>,\n 'wejścia': <gensim.models.keyedvectors.Vocab at 0x17e9207d488>,\n 'maja': <gensim.models.keyedvectors.Vocab at 0x17e9207d4c8>,\n 'cześć': <gensim.models.keyedvectors.Vocab at 0x17e9207d548>,\n 'stopniowo': <gensim.models.keyedvectors.Vocab at 0x17e9207d588>,\n 'tracąc': <gensim.models.keyedvectors.Vocab at 0x17e9207d448>,\n 'znaczenie': <gensim.models.keyedvectors.Vocab at 0x17e9207d608>,\n 'utrzymać': <gensim.models.keyedvectors.Vocab at 0x17e9207d5c8>,\n 'dzień': <gensim.models.keyedvectors.Vocab at 0x17e9207d788>,\n 'znajdowało': <gensim.models.keyedvectors.Vocab at 0x17e9207d748>,\n 'powiatu': <gensim.models.keyedvectors.Vocab at 0x17e9207d7c8>,\n 'lwowskiego': <gensim.models.keyedvectors.Vocab at 0x17e9207d988>,\n 'stanowiło': <gensim.models.keyedvectors.Vocab at 0x17e9207d8c8>,\n 'batalionu': <gensim.models.keyedvectors.Vocab at 0x17e9207d9c8>,\n 'batalion': <gensim.models.keyedvectors.Vocab at 0x17e9207da88>,\n 'przejęciu': <gensim.models.keyedvectors.Vocab at 0x17e9207da48>,\n 'straży_granicznej': <gensim.models.keyedvectors.Vocab at 0x17e9207db88>,\n 'pułku_piechoty': <gensim.models.keyedvectors.Vocab at 0x17e9207dc08>,\n 'wojnie': <gensim.models.keyedvectors.Vocab at 0x17e9207db08>,\n 'włączony': <gensim.models.keyedvectors.Vocab at 0x17e9207de08>,\n 'struktury': <gensim.models.keyedvectors.Vocab at 0x17e9207dd08>,\n 'brygady': <gensim.models.keyedvectors.Vocab at 0x17e9207de48>,\n 'podzielił': <gensim.models.keyedvectors.Vocab at 0x17e9207df08>,\n 'los': <gensim.models.keyedvectors.Vocab at 0x17e9207d0c8>,\n ...}"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "w2v_model.wv.vocab #podgląd na słowa występujące w słowniku"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trenowanie modelu gdzie:\n",
    "\n",
    "total_examples = całkowita liczba wszystkich zdań (w naszym przypadku liczba wszystkich artykułów);\n",
    "\n",
    "epochs = całkowita liczba iteracji (epochs) przejścia przez corpus - (10, 20, 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "4865\n"
    }
   ],
   "source": [
    "print(w2v_model.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "SS: at 11.59% examples, 57163 words/s, in_qsize 22, out_qsize 0\nINFO - 21:49:57: EPOCH 15 - PROGRESS: at 45.34% examples, 105372 words/s, in_qsize 22, out_qsize 2\nINFO - 21:49:58: EPOCH 15 - PROGRESS: at 83.80% examples, 126771 words/s, in_qsize 22, out_qsize 0\nINFO - 21:49:58: worker thread finished; awaiting finish of 10 more threads\nINFO - 21:49:58: worker thread finished; awaiting finish of 9 more threads\nINFO - 21:49:58: worker thread finished; awaiting finish of 8 more threads\nINFO - 21:49:58: worker thread finished; awaiting finish of 7 more threads\nINFO - 21:49:58: worker thread finished; awaiting finish of 6 more threads\nINFO - 21:49:58: worker thread finished; awaiting finish of 5 more threads\nINFO - 21:49:58: worker thread finished; awaiting finish of 4 more threads\nINFO - 21:49:58: worker thread finished; awaiting finish of 3 more threads\nINFO - 21:49:58: worker thread finished; awaiting finish of 2 more threads\nINFO - 21:49:58: worker thread finished; awaiting finish of 1 more threads\nINFO - 21:49:58: worker thread finished; awaiting finish of 0 more threads\nINFO - 21:49:58: EPOCH - 15 : training on 1232606 raw words (486867 effective words) took 3.3s, 148034 effective words/s\nINFO - 21:49:59: EPOCH 16 - PROGRESS: at 10.07% examples, 47407 words/s, in_qsize 22, out_qsize 0\nINFO - 21:50:00: EPOCH 16 - PROGRESS: at 44.17% examples, 99971 words/s, in_qsize 22, out_qsize 2\nINFO - 21:50:01: EPOCH 16 - PROGRESS: at 76.88% examples, 119531 words/s, in_qsize 21, out_qsize 1\nINFO - 21:50:01: worker thread finished; awaiting finish of 10 more threads\nINFO - 21:50:01: worker thread finished; awaiting finish of 9 more threads\nINFO - 21:50:01: worker thread finished; awaiting finish of 8 more threads\nINFO - 21:50:01: worker thread finished; awaiting finish of 7 more threads\nINFO - 21:50:01: worker thread finished; awaiting finish of 6 more threads\nINFO - 21:50:01: worker thread finished; awaiting finish of 5 more threads\nINFO - 21:50:01: worker thread finished; awaiting finish of 4 more threads\nINFO - 21:50:01: worker thread finished; awaiting finish of 3 more threads\nINFO - 21:50:01: worker thread finished; awaiting finish of 2 more threads\nINFO - 21:50:01: worker thread finished; awaiting finish of 1 more threads\nINFO - 21:50:01: worker thread finished; awaiting finish of 0 more threads\nINFO - 21:50:01: EPOCH - 16 : training on 1232606 raw words (487232 effective words) took 3.3s, 147173 effective words/s\nINFO - 21:50:02: EPOCH 17 - PROGRESS: at 11.86% examples, 52597 words/s, in_qsize 21, out_qsize 4\nINFO - 21:50:03: EPOCH 17 - PROGRESS: at 48.92% examples, 109162 words/s, in_qsize 22, out_qsize 0\nINFO - 21:50:04: EPOCH 17 - PROGRESS: at 95.21% examples, 141213 words/s, in_qsize 10, out_qsize 2\nINFO - 21:50:04: worker thread finished; awaiting finish of 10 more threads\nINFO - 21:50:04: worker thread finished; awaiting finish of 9 more threads\nINFO - 21:50:04: worker thread finished; awaiting finish of 8 more threads\nINFO - 21:50:04: worker thread finished; awaiting finish of 7 more threads\nINFO - 21:50:04: worker thread finished; awaiting finish of 6 more threads\nINFO - 21:50:04: worker thread finished; awaiting finish of 5 more threads\nINFO - 21:50:04: worker thread finished; awaiting finish of 4 more threads\nINFO - 21:50:04: worker thread finished; awaiting finish of 3 more threads\nINFO - 21:50:04: worker thread finished; awaiting finish of 2 more threads\nINFO - 21:50:04: worker thread finished; awaiting finish of 1 more threads\nINFO - 21:50:04: worker thread finished; awaiting finish of 0 more threads\nINFO - 21:50:04: EPOCH - 17 : training on 1232606 raw words (486924 effective words) took 3.3s, 149301 effective words/s\nINFO - 21:50:05: EPOCH 18 - PROGRESS: at 8.94% examples, 41934 words/s, in_qsize 21, out_qsize 0\nINFO - 21:50:06: EPOCH 18 - PROGRESS: at 43.45% examples, 101445 words/s, in_qsize 21, out_qsize 0\nINFO - 21:50:07: EPOCH 18 - PROGRESS: at 72.72% examples, 116085 words/s, in_qsize 21, out_qsize 0\nINFO - 21:50:08: worker thread finished; awaiting finish of 10 more threads\nINFO - 21:50:08: worker thread finished; awaiting finish of 9 more threads\nINFO - 21:50:08: worker thread finished; awaiting finish of 8 more threads\nINFO - 21:50:08: worker thread finished; awaiting finish of 7 more threads\nINFO - 21:50:08: worker thread finished; awaiting finish of 6 more threads\nINFO - 21:50:08: worker thread finished; awaiting finish of 5 more threads\nINFO - 21:50:08: worker thread finished; awaiting finish of 4 more threads\nINFO - 21:50:08: worker thread finished; awaiting finish of 3 more threads\nINFO - 21:50:08: worker thread finished; awaiting finish of 2 more threads\nINFO - 21:50:08: worker thread finished; awaiting finish of 1 more threads\nINFO - 21:50:08: worker thread finished; awaiting finish of 0 more threads\nINFO - 21:50:08: EPOCH - 18 : training on 1232606 raw words (486981 effective words) took 3.4s, 144215 effective words/s\nINFO - 21:50:09: EPOCH 19 - PROGRESS: at 13.16% examples, 55042 words/s, in_qsize 19, out_qsize 2\nINFO - 21:50:10: EPOCH 19 - PROGRESS: at 45.57% examples, 109224 words/s, in_qsize 21, out_qsize 0\nINFO - 21:50:11: EPOCH 19 - PROGRESS: at 76.67% examples, 122350 words/s, in_qsize 22, out_qsize 0\nINFO - 21:50:11: worker thread finished; awaiting finish of 10 more threads\nINFO - 21:50:11: worker thread finished; awaiting finish of 9 more threads\nINFO - 21:50:11: worker thread finished; awaiting finish of 8 more threads\nINFO - 21:50:11: worker thread finished; awaiting finish of 7 more threads\nINFO - 21:50:11: worker thread finished; awaiting finish of 6 more threads\nINFO - 21:50:11: worker thread finished; awaiting finish of 5 more threads\nINFO - 21:50:11: worker thread finished; awaiting finish of 4 more threads\nINFO - 21:50:11: worker thread finished; awaiting finish of 3 more threads\nINFO - 21:50:11: worker thread finished; awaiting finish of 2 more threads\nINFO - 21:50:11: worker thread finished; awaiting finish of 1 more threads\nINFO - 21:50:11: worker thread finished; awaiting finish of 0 more threads\nINFO - 21:50:11: EPOCH - 19 : training on 1232606 raw words (487265 effective words) took 3.2s, 150590 effective words/s\nINFO - 21:50:12: EPOCH 20 - PROGRESS: at 13.81% examples, 63150 words/s, in_qsize 21, out_qsize 1\nINFO - 21:50:13: EPOCH 20 - PROGRESS: at 47.03% examples, 109632 words/s, in_qsize 21, out_qsize 0\nINFO - 21:50:14: EPOCH 20 - PROGRESS: at 87.40% examples, 133291 words/s, in_qsize 21, out_qsize 2\nINFO - 21:50:14: worker thread finished; awaiting finish of 10 more threads\nINFO - 21:50:14: worker thread finished; awaiting finish of 9 more threads\nINFO - 21:50:14: worker thread finished; awaiting finish of 8 more threads\nINFO - 21:50:14: worker thread finished; awaiting finish of 7 more threads\nINFO - 21:50:14: worker thread finished; awaiting finish of 6 more threads\nINFO - 21:50:14: worker thread finished; awaiting finish of 5 more threads\nINFO - 21:50:14: worker thread finished; awaiting finish of 4 more threads\nINFO - 21:50:14: worker thread finished; awaiting finish of 3 more threads\nINFO - 21:50:14: worker thread finished; awaiting finish of 2 more threads\nINFO - 21:50:14: worker thread finished; awaiting finish of 1 more threads\nINFO - 21:50:14: worker thread finished; awaiting finish of 0 more threads\nINFO - 21:50:14: EPOCH - 20 : training on 1232606 raw words (487169 effective words) took 3.2s, 151747 effective words/s\nINFO - 21:50:15: EPOCH 21 - PROGRESS: at 12.54% examples, 56392 words/s, in_qsize 22, out_qsize 1\nINFO - 21:50:16: EPOCH 21 - PROGRESS: at 47.98% examples, 110381 words/s, in_qsize 22, out_qsize 1\nINFO - 21:50:17: EPOCH 21 - PROGRESS: at 86.27% examples, 132063 words/s, in_qsize 19, out_qsize 2\nINFO - 21:50:17: worker thread finished; awaiting finish of 10 more threads\nINFO - 21:50:17: worker thread finished; awaiting finish of 9 more threads\nINFO - 21:50:17: worker thread finished; awaiting finish of 8 more threads\nINFO - 21:50:17: worker thread finished; awaiting finish of 7 more threads\nINFO - 21:50:17: worker thread finished; awaiting finish of 6 more threads\nINFO - 21:50:18: worker thread finished; awaiting finish of 5 more threads\nINFO - 21:50:18: worker thread finished; awaiting finish of 4 more threads\nINFO - 21:50:18: worker thread finished; awaiting finish of 3 more threads\nINFO - 21:50:18: worker thread finished; awaiting finish of 2 more threads\nINFO - 21:50:18: worker thread finished; awaiting finish of 1 more threads\nINFO - 21:50:18: worker thread finished; awaiting finish of 0 more threads\nINFO - 21:50:18: EPOCH - 21 : training on 1232606 raw words (486917 effective words) took 3.2s, 150784 effective words/s\nINFO - 21:50:19: EPOCH 22 - PROGRESS: at 13.34% examples, 60564 words/s, in_qsize 21, out_qsize 0\nINFO - 21:50:20: EPOCH 22 - PROGRESS: at 45.94% examples, 109593 words/s, in_qsize 20, out_qsize 2\nINFO - 21:50:21: EPOCH 22 - PROGRESS: at 85.18% examples, 130542 words/s, in_qsize 19, out_qsize 2\nINFO - 21:50:21: worker thread finished; awaiting finish of 10 more threads\nINFO - 21:50:21: worker thread finished; awaiting finish of 9 more threads\nINFO - 21:50:21: worker thread finished; awaiting finish of 8 more threads\nINFO - 21:50:21: worker thread finished; awaiting finish of 7 more threads\nINFO - 21:50:21: worker thread finished; awaiting finish of 6 more threads\nINFO - 21:50:21: worker thread finished; awaiting finish of 5 more threads\nINFO - 21:50:21: worker thread finished; awaiting finish of 4 more threads\nINFO - 21:50:21: worker thread finished; awaiting finish of 3 more threads\nINFO - 21:50:21: worker thread finished; awaiting finish of 2 more threads\nINFO - 21:50:21: worker thread finished; awaiting finish of 1 more threads\nINFO - 21:50:21: worker thread finished; awaiting finish of 0 more threads\nINFO - 21:50:21: EPOCH - 22 : training on 1232606 raw words (487359 effective words) took 3.2s, 152347 effective words/s\nINFO - 21:50:22: EPOCH 23 - PROGRESS: at 11.86% examples, 57218 words/s, in_qsize 21, out_qsize 1\nINFO - 21:50:23: EPOCH 23 - PROGRESS: at 48.24% examples, 109212 words/s, in_qsize 17, out_qsize 5\nINFO - 21:50:24: worker thread finished; awaiting finish of 10 more threads\nINFO - 21:50:24: EPOCH 23 - PROGRESS: at 95.93% examples, 145713 words/s, in_qsize 9, out_qsize 1\nINFO - 21:50:24: worker thread finished; awaiting finish of 9 more threads\nINFO - 21:50:24: worker thread finished; awaiting finish of 8 more threads\nINFO - 21:50:24: worker thread finished; awaiting finish of 7 more threads\nINFO - 21:50:24: worker thread finished; awaiting finish of 6 more threads\nINFO - 21:50:24: worker thread finished; awaiting finish of 5 more threads\nINFO - 21:50:24: worker thread finished; awaiting finish of 4 more threads\nINFO - 21:50:24: worker thread finished; awaiting finish of 3 more threads\nINFO - 21:50:24: worker thread finished; awaiting finish of 2 more threads\nINFO - 21:50:24: worker thread finished; awaiting finish of 1 more threads\nINFO - 21:50:24: worker thread finished; awaiting finish of 0 more threads\nINFO - 21:50:24: EPOCH - 23 : training on 1232606 raw words (487160 effective words) took 3.2s, 151789 effective words/s\nINFO - 21:50:25: EPOCH 24 - PROGRESS: at 12.21% examples, 57117 words/s, in_qsize 21, out_qsize 0\nINFO - 21:50:26: EPOCH 24 - PROGRESS: at 45.78% examples, 106788 words/s, in_qsize 22, out_qsize 0\nINFO - 21:50:27: EPOCH 24 - PROGRESS: at 75.38% examples, 118838 words/s, in_qsize 18, out_qsize 4\nINFO - 21:50:27: worker thread finished; awaiting finish of 10 more threads\nINFO - 21:50:27: worker thread finished; awaiting finish of 9 more threads\nINFO - 21:50:27: worker thread finished; awaiting finish of 8 more threads\nINFO - 21:50:27: worker thread finished; awaiting finish of 7 more threads\nINFO - 21:50:27: worker thread finished; awaiting finish of 6 more threads\nINFO - 21:50:27: worker thread finished; awaiting finish of 5 more threads\nINFO - 21:50:27: worker thread finished; awaiting finish of 4 more threads\nINFO - 21:50:27: worker thread finished; awaiting finish of 3 more threads\nINFO - 21:50:27: worker thread finished; awaiting finish of 2 more threads\nINFO - 21:50:27: worker thread finished; awaiting finish of 1 more threads\nINFO - 21:50:27: worker thread finished; awaiting finish of 0 more threads\nINFO - 21:50:27: EPOCH - 24 : training on 1232606 raw words (487025 effective words) took 3.3s, 147423 effective words/s\nINFO - 21:50:28: EPOCH 25 - PROGRESS: at 12.21% examples, 57332 words/s, in_qsize 22, out_qsize 0\nINFO - 21:50:29: EPOCH 25 - PROGRESS: at 45.92% examples, 108017 words/s, in_qsize 21, out_qsize 2\nINFO - 21:50:30: EPOCH 25 - PROGRESS: at 82.82% examples, 129008 words/s, in_qsize 22, out_qsize 1\nINFO - 21:50:30: worker thread finished; awaiting finish of 10 more threads\nINFO - 21:50:30: worker thread finished; awaiting finish of 9 more threads\nINFO - 21:50:30: worker thread finished; awaiting finish of 8 more threads\nINFO - 21:50:30: worker thread finished; awaiting finish of 7 more threads\nINFO - 21:50:30: worker thread finished; awaiting finish of 6 more threads\nINFO - 21:50:30: worker thread finished; awaiting finish of 5 more threads\nINFO - 21:50:30: worker thread finished; awaiting finish of 4 more threads\nINFO - 21:50:31: worker thread finished; awaiting finish of 3 more threads\nINFO - 21:50:31: worker thread finished; awaiting finish of 2 more threads\nINFO - 21:50:31: worker thread finished; awaiting finish of 1 more threads\nINFO - 21:50:31: worker thread finished; awaiting finish of 0 more threads\nINFO - 21:50:31: EPOCH - 25 : training on 1232606 raw words (487050 effective words) took 3.2s, 150874 effective words/s\nINFO - 21:50:32: EPOCH 26 - PROGRESS: at 12.68% examples, 60387 words/s, in_qsize 21, out_qsize 1\nINFO - 21:50:33: EPOCH 26 - PROGRESS: at 47.42% examples, 110072 words/s, in_qsize 21, out_qsize 0\nINFO - 21:50:34: EPOCH 26 - PROGRESS: at 77.49% examples, 120581 words/s, in_qsize 22, out_qsize 1\nINFO - 21:50:34: worker thread finished; awaiting finish of 10 more threads\nINFO - 21:50:34: worker thread finished; awaiting finish of 9 more threads\nINFO - 21:50:34: worker thread finished; awaiting finish of 8 more threads\nINFO - 21:50:34: worker thread finished; awaiting finish of 7 more threads\nINFO - 21:50:34: worker thread finished; awaiting finish of 6 more threads\nINFO - 21:50:34: worker thread finished; awaiting finish of 5 more threads\nINFO - 21:50:34: worker thread finished; awaiting finish of 4 more threads\nINFO - 21:50:34: worker thread finished; awaiting finish of 3 more threads\nINFO - 21:50:34: worker thread finished; awaiting finish of 2 more threads\nINFO - 21:50:34: worker thread finished; awaiting finish of 1 more threads\nINFO - 21:50:34: worker thread finished; awaiting finish of 0 more threads\nINFO - 21:50:34: EPOCH - 26 : training on 1232606 raw words (487395 effective words) took 3.3s, 147563 effective words/s\nINFO - 21:50:35: EPOCH 27 - PROGRESS: at 12.31% examples, 58384 words/s, in_qsize 17, out_qsize 4\nINFO - 21:50:36: EPOCH 27 - PROGRESS: at 47.58% examples, 111405 words/s, in_qsize 21, out_qsize 0\nINFO - 21:50:37: EPOCH 27 - PROGRESS: at 83.43% examples, 128359 words/s, in_qsize 16, out_qsize 5\nINFO - 21:50:37: worker thread finished; awaiting finish of 10 more threads\nINFO - 21:50:37: worker thread finished; awaiting finish of 9 more threads\nINFO - 21:50:37: worker thread finished; awaiting finish of 8 more threads\nINFO - 21:50:37: worker thread finished; awaiting finish of 7 more threads\nINFO - 21:50:37: worker thread finished; awaiting finish of 6 more threads\nINFO - 21:50:37: worker thread finished; awaiting finish of 5 more threads\nINFO - 21:50:37: worker thread finished; awaiting finish of 4 more threads\nINFO - 21:50:37: worker thread finished; awaiting finish of 3 more threads\nINFO - 21:50:37: worker thread finished; awaiting finish of 2 more threads\nINFO - 21:50:37: worker thread finished; awaiting finish of 1 more threads\nINFO - 21:50:37: worker thread finished; awaiting finish of 0 more threads\nINFO - 21:50:37: EPOCH - 27 : training on 1232606 raw words (487294 effective words) took 3.2s, 150704 effective words/s\nINFO - 21:50:38: EPOCH 28 - PROGRESS: at 12.74% examples, 63240 words/s, in_qsize 19, out_qsize 0\nINFO - 21:50:39: EPOCH 28 - PROGRESS: at 47.01% examples, 107350 words/s, in_qsize 21, out_qsize 1\nINFO - 21:50:40: EPOCH 28 - PROGRESS: at 86.91% examples, 131520 words/s, in_qsize 21, out_qsize 0\nINFO - 21:50:40: worker thread finished; awaiting finish of 10 more threads\nINFO - 21:50:40: worker thread finished; awaiting finish of 9 more threads\nINFO - 21:50:40: worker thread finished; awaiting finish of 8 more threads\nINFO - 21:50:40: worker thread finished; awaiting finish of 7 more threads\nINFO - 21:50:40: worker thread finished; awaiting finish of 6 more threads\nINFO - 21:50:40: worker thread finished; awaiting finish of 5 more threads\nINFO - 21:50:40: worker thread finished; awaiting finish of 4 more threads\nINFO - 21:50:40: worker thread finished; awaiting finish of 3 more threads\nINFO - 21:50:40: worker thread finished; awaiting finish of 2 more threads\nINFO - 21:50:40: worker thread finished; awaiting finish of 1 more threads\nINFO - 21:50:40: worker thread finished; awaiting finish of 0 more threads\nINFO - 21:50:40: EPOCH - 28 : training on 1232606 raw words (487208 effective words) took 3.3s, 149510 effective words/s\nINFO - 21:50:41: EPOCH 29 - PROGRESS: at 14.35% examples, 66218 words/s, in_qsize 20, out_qsize 1\nINFO - 21:50:43: EPOCH 29 - PROGRESS: at 47.87% examples, 108785 words/s, in_qsize 22, out_qsize 0\nINFO - 21:50:44: EPOCH 29 - PROGRESS: at 84.79% examples, 127955 words/s, in_qsize 21, out_qsize 0\nINFO - 21:50:44: worker thread finished; awaiting finish of 10 more threads\nINFO - 21:50:44: worker thread finished; awaiting finish of 9 more threads\nINFO - 21:50:44: worker thread finished; awaiting finish of 8 more threads\nINFO - 21:50:44: worker thread finished; awaiting finish of 7 more threads\nINFO - 21:50:44: worker thread finished; awaiting finish of 6 more threads\nINFO - 21:50:44: worker thread finished; awaiting finish of 5 more threads\nINFO - 21:50:44: worker thread finished; awaiting finish of 4 more threads\nINFO - 21:50:44: worker thread finished; awaiting finish of 3 more threads\nINFO - 21:50:44: worker thread finished; awaiting finish of 2 more threads\nINFO - 21:50:44: worker thread finished; awaiting finish of 1 more threads\nINFO - 21:50:44: worker thread finished; awaiting finish of 0 more threads\nINFO - 21:50:44: EPOCH - 29 : training on 1232606 raw words (487074 effective words) took 3.3s, 148701 effective words/s\nINFO - 21:50:45: EPOCH 30 - PROGRESS: at 13.81% examples, 61730 words/s, in_qsize 20, out_qsize 0\nINFO - 21:50:46: EPOCH 30 - PROGRESS: at 47.19% examples, 106199 words/s, in_qsize 18, out_qsize 1\nINFO - 21:50:47: EPOCH 30 - PROGRESS: at 80.66% examples, 121511 words/s, in_qsize 21, out_qsize 0\nINFO - 21:50:47: worker thread finished; awaiting finish of 10 more threads\nINFO - 21:50:47: worker thread finished; awaiting finish of 9 more threads\nINFO - 21:50:47: worker thread finished; awaiting finish of 8 more threads\nINFO - 21:50:47: worker thread finished; awaiting finish of 7 more threads\nINFO - 21:50:47: worker thread finished; awaiting finish of 6 more threads\nINFO - 21:50:47: worker thread finished; awaiting finish of 5 more threads\nINFO - 21:50:47: worker thread finished; awaiting finish of 4 more threads\nINFO - 21:50:47: worker thread finished; awaiting finish of 3 more threads\nINFO - 21:50:47: worker thread finished; awaiting finish of 2 more threads\nINFO - 21:50:47: worker thread finished; awaiting finish of 1 more threads\nINFO - 21:50:47: worker thread finished; awaiting finish of 0 more threads\nINFO - 21:50:47: EPOCH - 30 : training on 1232606 raw words (487049 effective words) took 3.4s, 144764 effective words/s\nINFO - 21:50:47: training on a 36978180 raw words (14614208 effective words) took 99.9s, 146319 effective words/s\nTime to train the model: 1.66 mins\n"
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Zapis wytrenowanego modelu do pliku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "no input",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-5aa1b3a95068>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mw2v_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'X:\\\\Programming\\\\Python\\\\Pycharm\\\\Projects\\\\NLP\\\\venv\\\\w2v_model.bin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36msave_word2vec_format\u001b[1;34m(self, fname, fvocab, binary, total_vec)\u001b[0m\n\u001b[0;32m   1451\u001b[0m         \u001b[1;31m# from gensim.models.word2vec import save_word2vec_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1452\u001b[0m         _save_word2vec_format(\n\u001b[1;32m-> 1453\u001b[1;33m             fname, self.vocab, self.vectors, fvocab=fvocab, binary=binary, total_vec=total_vec)\n\u001b[0m\u001b[0;32m   1454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1455\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gensim\\models\\utils_any2vec.py\u001b[0m in \u001b[0;36m_save_word2vec_format\u001b[1;34m(fname, vocab, vectors, fvocab, binary, total_vec)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \"\"\"\n\u001b[0;32m    270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvocab\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mvectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"no input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtotal_vec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[0mtotal_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: no input"
     ]
    }
   ],
   "source": [
    "w2v_model.wv.save_word2vec_format('w2v_model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wczytanie zapisanego modelu\n",
    "Wczytanie zapisanego wcześniej modelu z pliku\n",
    "\n",
    "## Jeśli wytrenowaliśmy model na nowych parametrach należy pominąć poniższą komórkę "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO - 13:44:24: loading projection weights from w2v_model.bin\nINFO - 13:44:25: loaded (7161, 300) matrix from w2v_model.bin\n"
    }
   ],
   "source": [
    "w2v_model = KeyedVectors.load_word2vec_format(\"w2v_model.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1\n"
    }
   ],
   "source": [
    "w2v_model.wv.vocab #podgląd na słowa występujące w słowniku\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO - 13:44:37: precomputing L2-norms of word weight vectors\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('pałac', 0.786061704158783),\n ('zamku', 0.7524723410606384),\n ('królewski', 0.6971192359924316),\n ('książąt', 0.642208456993103),\n ('ruiny', 0.6317052245140076),\n ('gród', 0.6049981117248535),\n ('ratusz', 0.5893390774726868),\n ('murowany', 0.5868734121322632),\n ('królewskie', 0.5799057483673096),\n ('wzniesiono', 0.5479350090026855)]"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"zamek\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('święta', 0.7786576747894287),\n ('uroczystości', 0.7060004472732544),\n ('patrona', 0.6873683929443359),\n ('miłosierdzia_bożego', 0.6813386678695679),\n ('bożego', 0.6794769763946533),\n ('grobie', 0.6775121688842773),\n ('uroczystość', 0.6705838441848755),\n ('rocznicy', 0.6526843905448914),\n ('czci', 0.6455272436141968),\n ('obchodów', 0.6427680253982544)]"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"święto\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('gimnazjum', 0.8220643401145935),\n ('technikum', 0.819947361946106),\n ('liceum_ogólnokształcące', 0.8157960176467896),\n ('szkoły', 0.7762669324874878),\n ('szkole', 0.7579822540283203),\n ('zespół_szkół', 0.7516874074935913),\n ('naukę', 0.7291847467422485),\n ('szkoła', 0.7274847030639648),\n ('szkoły_podstawowej', 0.7118510007858276),\n ('stanisława_staszica', 0.7067950367927551)]"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"liceum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('dwukrotny', 0.7735169529914856),\n ('wicemistrz', 0.7612346410751343),\n ('brązowy_medalista', 0.7119187712669373),\n ('finalista', 0.6522637605667114),\n ('medalista_olimpijski', 0.6406358480453491),\n ('lekkoatleta', 0.638056218624115),\n ('uczestnik', 0.6361618638038635),\n ('mistrz_olimpijski', 0.6016188859939575),\n ('mistrzem', 0.5968785285949707),\n ('mistrzyni', 0.5881224274635315)]"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"mistrz\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('książę', 0.7753475904464722),\n ('królem', 0.742949366569519),\n ('fryderyk', 0.7417298555374146),\n ('władca', 0.7406895160675049),\n ('karol', 0.7358067035675049),\n ('panowanie', 0.7193434238433838),\n ('august', 0.6869291663169861),\n ('tron', 0.6838666200637817),\n ('habsburg', 0.681429386138916),\n ('dynastii', 0.6802775859832764)]"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"król\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('elżbieta', 0.830079197883606),\n ('królową', 0.799121081829071),\n ('królowej', 0.7824377417564392),\n ('elżbiety', 0.7071044445037842),\n ('szkocji', 0.5908934473991394),\n ('queen', 0.5388177037239075),\n ('królewska', 0.5307820439338684),\n ('walii', 0.5283026695251465),\n ('tronu', 0.527069091796875),\n ('mężem', 0.5260130763053894)]"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"królowa\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('żółty', 0.8178884983062744),\n ('niebieski', 0.8173955678939819),\n ('czarny', 0.7851782441139221),\n ('białym', 0.7674051523208618),\n ('czarnym', 0.7511237859725952),\n ('kolorze', 0.7400006055831909),\n ('zielony', 0.7337899208068848),\n ('koloru', 0.7334598898887634),\n ('czerwonym', 0.6677516102790833),\n ('czarne', 0.6507636308670044)]"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"kolor\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('mazda', 0.8115215301513672),\n ('mustanga', 0.7985462546348572),\n ('samochodu', 0.7895808815956116),\n ('nadwozia', 0.7857412695884705),\n ('samochód', 0.761103093624115),\n ('auta', 0.75453782081604),\n ('mustang', 0.7527592182159424),\n ('modele', 0.747249960899353),\n ('zawieszenie', 0.7194379568099976),\n ('samochodem', 0.715705931186676)]"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"auto\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('duża', 0.6930006146430969),\n ('wzrosła', 0.6708990335464478),\n ('zarejestrowanych', 0.6533222794532776),\n ('wynosiła', 0.6461988687515259),\n ('procent', 0.6381279826164246),\n ('wyniosła', 0.622017502784729),\n ('liczby', 0.6190260052680969),\n ('ilość', 0.6142896413803101),\n ('mężczyzn_kobiet', 0.610946536064148),\n ('łączna', 0.5991466045379639)]"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"liczba\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('zmniejszenie', 0.7458816170692444),\n ('największej', 0.7203786373138428),\n ('procent', 0.7080565094947815),\n ('danym', 0.6865778565406799),\n ('większej', 0.6767949461936951),\n ('liczbę', 0.6733611822128296),\n ('stałych', 0.6545504331588745),\n ('najmniej', 0.6334962844848633),\n ('odpowiednio', 0.6240201592445374),\n ('różnica', 0.6200425624847412)]"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"liczby\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"pięć\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"wzrost\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"polska\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"francja\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"język\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"złoto\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"książka\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"owoce\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"noc\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"kot\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"program\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"gra\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"gry\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"grę\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gdy już nie planujemy dalej trenować modelu, wywołujemy funkcję init_sims (), co sprawi, że model będzie znacznie bardziej wydajny pod względem pamięci:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.init_sims(replace=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python37964bitca77a13e3c514d86bfffd9573ea2a29a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}